# Neat Workflows 

Neat workflows allow users to automate complex processes involving multiple steps and systems. The workflow engine is a software system that automates the data transformation process for a knowledge graph system. The workflow is designed to be modular and scalable, allowing users to add or remove steps as needed.

The workflow consists of the following sub-components: 

- **Workflow steps defintion class** - individual tasks that make up the workflow and defined as python functions. All steps are aggregated into a single workflow class.
- **Workflow configurations** - a set of parameters that define how the workflow should be executed. The configuration is defined in a YAML manifest file.
- **Transformation rules** - a set of rules that define how the data should be transformed from the source graph to the solution graph. The rules are defined as Excel file.

### Setup and Configuration:

To set up and configure the workflow engine, follow these steps:

1. Download the workflow 
2. Configure the parameters in the manifest file to match your system requirements
3. Execute the workflow using the command line or a GUI tool
4. Monitor the progress of the workflow and any errors that may occur

### Using the Workflow:

The workflow engine follows a modular, step-by-step process that can be customized to suit your specific data transformation needs. Each step in the workflow corresponds to a specific task, such as loading transformation rules, configuring graph stores, and loading the source graph.
Users can customize the workflow by adding or removing steps, or by modifying the parameters in each step to match their specific data requirements.

### Troubleshooting:

In the event of errors or issues with the workflow engine, users should consult the log files generated by the engine for detailed error messages. The log files should provide information on the specific step in the workflow that caused the error, as well as any relevant error messages or stack traces.
Users can also consult the documentation for each step in the workflow for troubleshooting tips and best practices. In addition, the workflow engine may include built-in error handling and recovery mechanisms that can help mitigate errors and ensure that the workflow continues to execute even in the event of issues.

Overall, NEAT workflows designed to automate the data transformation process for a knowledge graph system, allowing users to easily and efficiently transform large amounts of data in a scalable and modular way. With the right setup, configuration, and troubleshooting processes in place, the workflow engine can help users unlock the full potential of their knowledge graph system.

### Basic NEAT workflow definition 

```python
import logging

from cognite.client import CogniteClient

from cognite.neat.core.workflow.base import BaseWorkflow
from cognite.neat.core.workflow.model import FlowMessage


class BasicNeatWorkflow(BaseWorkflow):
    def __init__(self, name: str, client: CogniteClient):
        super().__init__(name, client, [])
        self.counter = 0

    def step_run_experiment_1(self, flow_msg: FlowMessage = None):
        logging.info("Running experiment 1")
        logging.info("Done running experiment 4444")
        self.counter = self.counter + 1
        logging.info("Counter: " + str(self.counter))
        if self.counter > 5:
            return FlowMessage(output_text="Done running experiment", next_step_ids=["error_handler"])
        else:
            return FlowMessage(
                output_text=f"Running iteration {self.counter} of xperiment", next_step_ids=["run_experiment_1"]
            )

    def step_cleanup(self, flow_msg: FlowMessage = None):
        logging.info("Cleanup")

    def step_error_handler(self, flow_msg: FlowMessage = None):
        logging.info("Error handler")
        return FlowMessage(output_text="Error handleed")

``` 

Rules and conventions: 

- Each workflow must reside in its own folder and folder name defines workflow name. 
- Workflow class name must end with `NeatWorkflow` , for example `BasicNeatWorkflow` and must implement `BaseWorkflow` class from `from cognite.neat.core.workflow.base`
- Workflow folder must contain at least 2 files :
    - `workflow.py` - steps implementation file
    - `workflow.yaml` - manifest and configurations
- Each method that should be orchestrated by workflow engine must be prefixed with `step_` , each method must have single argument of `FlowMessage` type and return `FlowMessage` or `None`.
- FlowMessage is passed from one step to another and it's captured in execution log.
- FlowMessage can have `next_step_ids` property that defines which steps should be executed next. If `next_step_ids` is not set, next step will be executed based on execution graph defined in manifest. 
- FlowMessage can have `output_text` property that defines what should be logged in execution log and available in UI. If `output_text` is not set, method name will be used as output text.
- FlowMessage can have `error_text` property that defines error message that should be logged in execution log and available in UI in case of error. 

Manifest file consist of 3 main sections: 
- `configs` - workflow configuration parameters.
- `steps` - workflow steps metadata. 
- `groups` - workflow groups is logical grouping of steps, it's used for documentation and UI purposes.
- `description` - workflow description.
- `implementation_module` - alternative workflow implementation module name.If not set, `workflow.py` will be used. 



manifest.yaml example:
```yaml

configs:
-   group: source_rdf_store
    label: null
    name: source_rdf_store.type
    options: null
    required: false
    type: null
    value: graphdb
description: null
groups:
-   description: null
    id: experimentation_system
    label: Experimentation playground
    tranistion_to: null
    ui_config:
        pos_x: 171
        pos_y: 6
implementation_module: null
name: playground
steps:
-   description: null
    enabled: true
    group_id: null
    id: run_experiment_1
    label: Running experiment
    method: null
    params: {}
    stype: pystep
    transition_to:
    - cleanup
    - error_handler
    trigger: false
    ui_config:
        pos_x: 340
        pos_y: 144
-   description: null
    enabled: true
    group_id: null
    id: cleanup
    label: Cleanup
    method: null
    params: null
    stype: pystep
    transition_to: []
    trigger: false
    ui_config:
        pos_x: 340
        pos_y: 448
-   description: null
    enabled: true
    group_id: null
    id: step_trigger
    label: HTTP trigger
    method: null
    params: {}
    stype: http_trigger
    transition_to:
    - run_experiment_1
    trigger: true
    ui_config:
        pos_x: 336
        pos_y: 44
-   description: null
    enabled: false
    group_id: null
    id: step_295076
    label: Run every 10 sec
    method: null
    params:
        interval: every 10 seconds
    stype: time_trigger
    transition_to:
    - run_experiment_1
    trigger: true
    ui_config:
        pos_x: 544
        pos_y: 42
-   description: null
    enabled: true
    group_id: null
    id: error_handler
    label: Error handler
    method: null
    params: {}
    stype: pystep
    transition_to:
    - cleanup
    trigger: false
    ui_config:
        pos_x: 496
        pos_y: 300
```

### Versioning 


### Workflow configuration parameters

Each workflow can have configuration parameters that can be set in manifest file directly or via UI. In addition to that, workflow can have system configuration parameters that have special meaning . 
Supported system configuration parameters : 

- `system.execution_reporting_type` - controls how workflow execution log should be reported to CDF . Supported values : `all_disabled`, `all_enabled`(default) 

Example :
```yaml
-   group: system
    name: system.execution_reporting_type
    value: all_disabled
```

### Triggers 

Trigger is a special type of step that can be used to trigger workflow execution. 

Supported trigger types :

- `http_trigger` - HTTP trigger that can be used to trigger workflow execution via HTTP request.Also use by UI to trigger workflow execution.
- `time_trigger` - time trigger that can be used to trigger workflow execution on schedule.

### Tasks 

Task is a special type of step that has provided implementation (no need to implement it in *workflow.py*) and can be used to perform some common tasks. Task are configured via `params` section in manifest file. 

Supported task types : 

- `start_workflow_task_step` - start another workflow. FlowMessage is passed to started workflow as input. The task supports synchronious and asynchronious execution. 


### Packaging and automatic resource loading 

Workflows are packaged as zip files and can be loaded from local file system or from CDF Files.

### Workflow sharing and remote storage 

NEAT supports workflow sharing and storage via CDF. 

### Execution history 

NEAT stores detailed execution history in CDF.

### REST API 

http://localhost:8000/docs 


### Monitoring and metrics 


NEAT by default exposes prometheus metrics on http://localhost:8080/metrics


