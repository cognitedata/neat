{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Input Data - Graph Extraction\n",
    "\n",
    "[![Notebook](https://shields.io/badge/notebook-access-green?logo=jupyter&style=for-the-badge)](https://github.com/cognitedata/neat/blob/main/docs/tutorial/notebooks/part-2-knowledge-graph-generation.ipynb)\n",
    "\n",
    "\n",
    "* author: Nikola Vasiljevic, Anders Albert\n",
    "* date: 2023-10-22\n",
    "\n",
    "**Prerequisite**: \n",
    " * Installed Python with `excel` dependency `pip install cognite-neat[excel]`\n",
    " * Completed tutorial [Part 1](part-1-data-model-generation.html)\n",
    "\n",
    "**Content** This notebook represent Part 2 of NEAT Onboarding tutorial, in it we will demonstrate how to extract data into `neat`'s knowledge graph.\n",
    "\n",
    "After importing or creating the *Rules* you are ready to extract some data.\n",
    "\n",
    "`neat` supports multiple ways of ways of extracting data from a source into `neat`'s knowledge graph (aka `NeatGraphStore`), which is `neat`'s internal storage for data. Once the data has been extracted into `neat`, we can export it from `neat` to various formats such as `instances` and `asset` + `relationships`. \n",
    "\n",
    "With completion of this notebook you will be familiar with both Data Modeling Flow and Graph ETL Flow, as shown in the figure below:\n",
    "\n",
    "Data modeling flow in `neat` are visually presented in the figure below:\n",
    "\n",
    "![NEAT Flows](../../figs/neat-two_flows.png)\n",
    "\n",
    "The two extraction methods we will cover in this tutorial are:\n",
    "1. Generating mock data using `neat` mock module.\n",
    "2. Manual creation with the help of the Graph Capturing Sheet.\n",
    "\n",
    "These might seems like trivial use cases, however, both of these approaches has useful applications. First, if is often is useful to test how knowledge graph based on certain data model will function, for example, how queries would perform if we have very large knowledge graphs or very deep knowledge graph (many hops). In this case, creating a lot of mock data is useful. Another case is when we do not have knowledge graphs per se. Instead we have scattered and unconnected information which needs to be bring together to form knowledge graph. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with importing the same examples rules as we used in Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.neat.rules import importer\n",
    "from cognite.neat.rules.examples import power_grid_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_rules = importer.ExcelImporter(power_grid_model).to_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Mock Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by inspecting the classes we have in the *Transformation Rules*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cdf_resource_type</th>\n",
       "      <th>deprecated</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>parent_asset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Asset</td>\n",
       "      <td>False</td>\n",
       "      <td>GeographicalRegion</td>\n",
       "      <td>GeographicalRegion</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A subset of a geographical region of a power s...</td>\n",
       "      <td>Asset</td>\n",
       "      <td>False</td>\n",
       "      <td>SubGeographicalRegion</td>\n",
       "      <td>SubGeographicalRegion</td>\n",
       "      <td>GeographicalRegion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A substation is a part of an electrical genera...</td>\n",
       "      <td>Asset</td>\n",
       "      <td>False</td>\n",
       "      <td>Substation</td>\n",
       "      <td>Substation</td>\n",
       "      <td>SubGeographicalRegion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Asset</td>\n",
       "      <td>False</td>\n",
       "      <td>Terminal</td>\n",
       "      <td>Terminal</td>\n",
       "      <td>Substation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classes(data={'GeographicalRegion': Class(validators_to_skip=set(), description=None, cdf_resource_type='Asset', deprecated=False, deprecation_date=None, replaced_by=None, source=None, source_entity_name=None, match_type=None, comment=None, class_id='GeographicalRegion', class_name='GeographicalRegion', parent_class=None, parent_asset=None, Dataset Id=nan, similarTo=nan, similarityScore=nan, equalTo=nan), 'SubGeographicalRegion': Class(validators_to_skip=set(), description='A subset of a geographical region of a power system network model.', cdf_resource_type='Asset', deprecated=False, deprecation_date=None, replaced_by=None, source=None, source_entity_name=None, match_type=None, comment=None, class_id='SubGeographicalRegion', class_name='SubGeographicalRegion', parent_class=None, parent_asset='GeographicalRegion', Dataset Id=nan, similarTo=nan, similarityScore=nan, equalTo=nan), 'Substation': Class(validators_to_skip=set(), description='A substation is a part of an electrical generation, transmission, and distribution system.', cdf_resource_type='Asset', deprecated=False, deprecation_date=None, replaced_by=None, source=None, source_entity_name=None, match_type=None, comment=None, class_id='Substation', class_name='Substation', parent_class=None, parent_asset='SubGeographicalRegion', Dataset Id=nan, similarTo=nan, similarityScore=nan, equalTo=nan), 'Terminal': Class(validators_to_skip=set(), description=None, cdf_resource_type='Asset', deprecated=False, deprecation_date=None, replaced_by=None, source=None, source_entity_name=None, match_type=None, comment=None, class_id='Terminal', class_name='Terminal', parent_class=None, parent_asset='Substation', Dataset Id=nan, similarTo=nan, similarityScore=nan, equalTo=nan)})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_rules.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have 4 different types of classes. To generate mock data for these classes, we write up the following dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = {\"GeographicalRegion\":5,\n",
    "               \"SubGeographicalRegion\":10,\n",
    "               \"Substation\": 20,\n",
    "               \"Terminal\": 60}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to setup the `neat` knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.neat.graph import NeatGraphStore\n",
    "\n",
    "store = NeatGraphStore.from_rules(power_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data in `neat` is represented as triples as we use RDF to represent data, and SPARQL to interact with it internally. For more information see [Resource Description Framework](https://en.wikipedia.org/wiki/Resource_Description_Framework) and [SPARQL](https://en.wikipedia.org/wiki/SPARQL)\n",
    "\n",
    "To create the mock data we use the following call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.neat.graph import extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = extractors.MockGraphGenerator(power_rules).generate_triples(class_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add these triples into the `neat` store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.add_triples(triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the store by running the following query on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.neat.utils import remove_namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminal                  60\n",
      "Substation                20\n",
      "SubGeographicalRegion     10\n",
      "GeographicalRegion        5\n"
     ]
    }
   ],
   "source": [
    "for res in list(store.graph.query(\"\"\"\n",
    "SELECT ?class (count(?s) as ?instances )\n",
    "WHERE { ?s a ?class . }\n",
    "GROUP BY ?class\n",
    "ORDER BY DESC(?instances)\"\"\")):\n",
    "    print(f\"{remove_namespace(res[0]):25} {res[1]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Extraction with Graph Capturing Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, lets inspect the classes available in the *Transformation Rules*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cdf_resource_type</th>\n",
       "      <th>deprecated</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>parent_asset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Asset</td>\n",
       "      <td>False</td>\n",
       "      <td>GeographicalRegion</td>\n",
       "      <td>GeographicalRegion</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A subset of a geographical region of a power s...</td>\n",
       "      <td>Asset</td>\n",
       "      <td>False</td>\n",
       "      <td>SubGeographicalRegion</td>\n",
       "      <td>SubGeographicalRegion</td>\n",
       "      <td>GeographicalRegion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A substation is a part of an electrical genera...</td>\n",
       "      <td>Asset</td>\n",
       "      <td>False</td>\n",
       "      <td>Substation</td>\n",
       "      <td>Substation</td>\n",
       "      <td>SubGeographicalRegion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Asset</td>\n",
       "      <td>False</td>\n",
       "      <td>Terminal</td>\n",
       "      <td>Terminal</td>\n",
       "      <td>Substation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classes(data={'GeographicalRegion': Class(validators_to_skip=set(), description=None, cdf_resource_type='Asset', deprecated=False, deprecation_date=None, replaced_by=None, source=None, source_entity_name=None, match_type=None, comment=None, class_id='GeographicalRegion', class_name='GeographicalRegion', parent_class=None, parent_asset=None, Dataset Id=nan, similarTo=nan, similarityScore=nan, equalTo=nan), 'SubGeographicalRegion': Class(validators_to_skip=set(), description='A subset of a geographical region of a power system network model.', cdf_resource_type='Asset', deprecated=False, deprecation_date=None, replaced_by=None, source=None, source_entity_name=None, match_type=None, comment=None, class_id='SubGeographicalRegion', class_name='SubGeographicalRegion', parent_class=None, parent_asset='GeographicalRegion', Dataset Id=nan, similarTo=nan, similarityScore=nan, equalTo=nan), 'Substation': Class(validators_to_skip=set(), description='A substation is a part of an electrical generation, transmission, and distribution system.', cdf_resource_type='Asset', deprecated=False, deprecation_date=None, replaced_by=None, source=None, source_entity_name=None, match_type=None, comment=None, class_id='Substation', class_name='Substation', parent_class=None, parent_asset='SubGeographicalRegion', Dataset Id=nan, similarTo=nan, similarityScore=nan, equalTo=nan), 'Terminal': Class(validators_to_skip=set(), description=None, cdf_resource_type='Asset', deprecated=False, deprecation_date=None, replaced_by=None, source=None, source_entity_name=None, match_type=None, comment=None, class_id='Terminal', class_name='Terminal', parent_class=None, parent_asset='Substation', Dataset Id=nan, similarTo=nan, similarityScore=nan, equalTo=nan)})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_rules.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now inspect properties related to one of the classes. Here we can see that class `Substation` contains two properties. First property in the list, `name`, contains value of type string, this type of property in semantic data modeling is known as data type properties, or in general graph theory this property is a node attribute, where node is equivalent to class instance. The second property, `subGeographicalRegon`, contains a link to `SubGeographicalRegion` instance. This type of property in the semantic data modeling is known as object properties, while in general graph theory this property represent an edge that connect nodes of two types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_name</th>\n",
       "      <th>property_type</th>\n",
       "      <th>expected_value_type</th>\n",
       "      <th>min_count</th>\n",
       "      <th>max_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>DatatypeProperty</td>\n",
       "      <td>{'prefix': 'xsd', 'suffix': 'string', 'name': ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subGeographicalRegion</td>\n",
       "      <td>ObjectProperty</td>\n",
       "      <td>{'prefix': 'power-grid', 'suffix': 'SubGeograp...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           property_name     property_type  \\\n",
       "0                   name  DatatypeProperty   \n",
       "1  subGeographicalRegion    ObjectProperty   \n",
       "\n",
       "                                 expected_value_type  min_count  max_count  \n",
       "0  {'prefix': 'xsd', 'suffix': 'string', 'name': ...          1          1  \n",
       "1  {'prefix': 'power-grid', 'suffix': 'SubGeograp...          1          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"property_name\", \"property_type\", \"expected_value_type\", \"min_count\", \"max_count\"]\n",
    "power_rules.properties.groupby(\"class_id\")[\"Substation\"].to_pandas(include=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the above data model to generate what we call `Graph Capturing Sheet` which is tailored Excel sheet containing:\n",
    "- sheets for each of the defined classes\n",
    "- columns corresponding to each property defined in data model\n",
    "\n",
    "This sheet is generate using method `rules2graph_capturing_sheet` which is part of `extractors`. The method contains following arguments:\n",
    "\n",
    "- `transformation_rules` : which is instance of transformation rules that contain definition of data model\n",
    "- `file_path`: path where the graph capturing sheet should be stored\n",
    "- `no_rows`: represent expected maximum number rows each sheet will have, thus corresponding to maximum of instance of any of define classes, by default set to 10000\n",
    "- `auto_identifier_type` : type of auto identifier to be made for each class instance, by default set to `index` meaning `index-based` identifiers where index is row number\n",
    "- `add_drop_down_list`: flag indicating whether to provide drop down selection of identifiers (i.e. links) for object type properties (i.e., edges)\n",
    "\n",
    "We will use default values for arguments, meaning, automatic identifiers based on indexes, 10 000 rows, and drop down menus for object type properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.neat.graph import extractors\n",
    "\n",
    "extractors.GraphCapturingSheet(power_rules, \"power-grid-graph-capture.xlsx\").create_template(overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the animated gif below one can see how generated graph capturing sheet looks as well how process of capturing graph is conveyed.\n",
    "\n",
    "\n",
    "<video src=\"../../videos/tutorial-2-graph-capturing-sheet.mp4\" controls>\n",
    "</video>\n",
    "\n",
    "\n",
    "A row in a sheet represent an instance of a class. As one enters values for property in column `B`, the identifier is automatically added.\n",
    "As we define instances, their identifier become in drop down menus for properties which are \"edges\" between \"nodes\". By connecting \"nodes\" we make a knowledge graph.\n",
    "\n",
    "Let's now convert now filled graph capturing sheet into knowledge graph. First, we will create empty graph store object, then load raw sheet, and finally convert the raw sheet to graph using previously defined data model in transformation rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_sheet = extractors.GraphCapturingSheet(power_rules, \"examples/power-grid-example.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = existing_sheet.extract_triples_from_sheet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you skipped the first part of this tutorial, we import the `NeatGraphStore` and initialize a new instance of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.neat.graph import NeatGraphStore\n",
    "\n",
    "store = NeatGraphStore.from_rules(power_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.add_triples(triples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check graph content we can execute `SPARQL` to count all the class instances:\n",
    "```\n",
    "SELECT ?class (count(?s) as ?instances ) WHERE { ?s a ?class . } group by ?class order by DESC(?instances)\n",
    "```\n",
    "\n",
    "and later on when processing results we are purposely removing namespaces from the class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeographicalRegion        2\n",
      "SubGeographicalRegion     2\n",
      "Substation                2\n",
      "Terminal                  2\n"
     ]
    }
   ],
   "source": [
    "from cognite.neat.utils import remove_namespace\n",
    "\n",
    "for res in list(store.graph.query(\"SELECT ?class (count(?s) as ?instances ) WHERE { ?s a ?class . } group by ?class order by DESC(?instances)\")):\n",
    "    print(f\"{remove_namespace(res[0]):25} {res[1]}\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we have two instances of each class that we captured through graph capturing sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb4cf576dcffa0a787a8982645e03a998957c06d661d178298ccc8dde5bf89f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
